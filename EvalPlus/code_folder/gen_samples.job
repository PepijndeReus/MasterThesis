#!/bin/bash

#SBATCH --partition=gpu
#SBATCH --gpus=1
#SBATCH --job-name=Gen_samples
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=18
#SBATCH --time=01:00:00
#SBATCH --output=./job_output/GenSamples_512_%A.out

module purge
module load 2023

# Activate conda environment
source activate thesis

# Run your codes
# 02-05-2024 disable generate samples, first get sanitize working
echo -e "\nGenerate samples...\n"
srun python -u GenerateSamples.py

echo -e "\nSamples generated.\nProceeding to sanitizing..\n"
# run in code_folder: python evalplus/sanitize.py --samples samples_max_tokens_128.jsonl
srun python evalplus/sanitize.py --samples samples_max_tokens_512.jsonl
# srun evalplus.syncheck --samples samples_max_tokens_128.jsonl --dataset humaneval

#echo -e "\nEvaluate sanitized samples 128...\n"
#srun evalplus.evaluate --dataset humaneval --samples samples_max_tokens_128-sanitized.jsonl
#echo -e "\nEvaluate sanitized samples 256...\n"
#srun evalplus.evaluate --dataset humaneval --samples samples_max_tokens_256-sanitized.jsonl
echo -e "\nEvaluate sanitized samples 512...\n"
srun evalplus.evaluate --dataset humaneval --samples samples_max_tokens_512-sanitized.jsonl

# evaluatie with docker
# docker run -v $(pwd):/app ganler/evalplus:latest --dataset [humaneval|mbpp] --samples samples.jsonl