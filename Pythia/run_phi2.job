#!/bin/bash

#SBATCH --partition=gpu
#SBATCH --gpus=1
#SBATCH --job-name=Phi2
#SBATCH --ntasks=1
#SBATCH --time=00:20:00
#SBATCH --output=./job_out/Phi2_%A.out
#SBATCH --ear=on
#SBATCH --ear-policy=monitoring
#SBATCH --ear-user-db=ear/Pythia

module purge
module load 2023
module load Python/3.11.3-GCCcore-12.3.0
module load cuDNN/8.9.2.26-CUDA-12.1.1
module load PyTorch/2.1.2-foss-2023a-CUDA-12.1.1

# Activate conda environments
source activate thesis

(cd ./lm-checkpoints && pip3 install --user ."[eval]")
pip3 install --user "lm-checkpoints[eval]"

# Clear CUDA cache before starting the task
python -c "import torch; torch.cuda.empty_cache()"

OUTPUT_DIR="./results"

# perform 250 runs of code2text_python task using Phi-2 model
lm_eval \
    --model hf \
    --model_args pretrained=microsoft/phi-2,trust_remote_code=True \
    --tasks code2text_python \
    --device cuda \
    --batch_size 2 \
    --limit 250 \
    --output_path $OUTPUT_DIR/Phi2
